"""
å°è©±çŸ¥è­˜æå–å™¨ç¤ºç¯„è…³æœ¬
Conversation Extractor Demo Script

ç¤ºç¯„å¦‚ä½•ä½¿ç”¨ ConversationExtractor ä¾†åˆ†æå’Œè™•ç†å°è©±è¨˜éŒ„
"""

import os
import sys

# å°‡ particle_core/src åŠ å…¥è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from conversation_extractor import ConversationExtractor


def demo_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºç¯„"""
    print("=" * 60)
    print("ğŸ“š ç¤ºç¯„ 1ï¼šåŸºæœ¬å°è©±æ‰“åŒ…èˆ‡å°å‡º")
    print("=" * 60)
    
    # å»ºç«‹æ¸¬è©¦å°è©±
    conversation = [
        {
            "role": "user",
            "content": "è«‹å•ä»€éº¼æ˜¯ç²’å­èªè¨€æ ¸å¿ƒç³»çµ±ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "ç²’å­èªè¨€æ ¸å¿ƒç³»çµ±ï¼ˆParticle Language Coreï¼‰æ˜¯ä¸€å€‹å‰µæ–°çš„é‚è¼¯åŸ·è¡Œæ¡†æ¶ã€‚å®ƒå°‡è¨ˆç®—é‚è¼¯æŠ½è±¡ç‚ºã€Œç¨®å­ã€æ¦‚å¿µï¼Œé€šéã€Œå…±æŒ¯ã€æ©Ÿåˆ¶å¯¦ç¾è·¨é ˜åŸŸçš„è¨ˆç®—å”åŒã€‚ç³»çµ±æ¡ç”¨äº”éšæ®µåŸ·è¡Œæ¨¡å¼ï¼šSTRUCTURE â†’ MARK â†’ FLOW â†’ RECURSE â†’ STOREï¼Œç¢ºä¿é‚è¼¯çš„å®Œæ•´æ€§å’Œå¯è¿½æº¯æ€§ã€‚"
        },
        {
            "role": "user",
            "content": "å®ƒå’Œå‚³çµ±çš„ç·¨ç¨‹ç¯„å¼æœ‰ä»€éº¼ä¸åŒï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "å‚³çµ±ç·¨ç¨‹ç¯„å¼å°ˆæ³¨æ–¼æŒ‡ä»¤åºåˆ—å’Œæ•¸æ“šçµæ§‹ï¼Œè€Œç²’å­èªè¨€æ ¸å¿ƒç³»çµ±é—œæ³¨ã€Œé‚è¼¯ç¨®å­ã€çš„çµ„åˆèˆ‡å…±æŒ¯ã€‚å› æ­¤ï¼Œå®ƒæ›´æ¥è¿‘è‡ªç„¶èªè¨€çš„è¡¨é”æ–¹å¼ï¼Œå…·æœ‰æ›´å¥½çš„å¯è®€æ€§å’Œå¯ç¶­è­·æ€§ã€‚æ­¤å¤–ï¼Œç³»çµ±æ”¯æŒè¨˜æ†¶å°å­˜å’Œç‹€æ…‹æ¢å¾©ï¼Œå¯ä»¥åœ¨ä¸åŒåŸ·è¡Œç’°å¢ƒé–“ç„¡ç¸«é·ç§»ã€‚"
        }
    ]
    
    # åˆå§‹åŒ–æå–å™¨
    extractor = ConversationExtractor()
    
    # æ‰“åŒ…å°è©±
    package = extractor.package_conversation(
        conversation,
        metadata={
            "title": "ç²’å­èªè¨€æ ¸å¿ƒç³»çµ±ä»‹ç´¹",
            "date": "2026-01-04",
            "tags": ["ç²’å­èªè¨€", "é‚è¼¯åŸ·è¡Œ", "ç³»çµ±æ¶æ§‹"]
        }
    )
    
    print(f"\nâœ“ å°è©±å·²æ‰“åŒ…")
    print(f"  - ç¸½è¨Šæ¯æ•¸: {package['statistics']['total_messages']}")
    print(f"  - ç¸½å­—ç¬¦æ•¸: {package['statistics']['total_chars']}")
    print(f"  - å¹³å‡å›è¦†é•·åº¦: {package['statistics']['avg_assistant_length']:.0f} å­—ç¬¦")
    
    # å°å‡ºç‚ºä¸åŒæ ¼å¼
    os.makedirs("/tmp/conversation_demo", exist_ok=True)
    
    extractor.export_to_file(package, "/tmp/conversation_demo/demo.json", "json")
    extractor.export_to_file(package, "/tmp/conversation_demo/demo.md", "markdown")
    extractor.export_to_file(package, "/tmp/conversation_demo/demo.txt", "txt")
    
    print("\nâœ“ å·²å°å‡ºæ‰€æœ‰æ ¼å¼åˆ° /tmp/conversation_demo/")


def demo_attention_analysis():
    """æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æç¤ºç¯„"""
    print("\n" + "=" * 60)
    print("ğŸ¯ ç¤ºç¯„ 2ï¼šæ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æ")
    print("=" * 60)
    
    conversation = [
        {
            "role": "user",
            "content": "æˆ‘æƒ³å­¸ç¿’å¦‚ä½•éƒ¨ç½² Kubernetes æ‡‰ç”¨ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "éƒ¨ç½² Kubernetes æ‡‰ç”¨éœ€è¦ç†è§£å¹¾å€‹æ ¸å¿ƒæ¦‚å¿µï¼šPodã€Deploymentã€Serviceã€ConfigMap å’Œ Secretã€‚é¦–å…ˆï¼ŒPod æ˜¯æœ€å°çš„éƒ¨ç½²å–®å…ƒï¼ŒåŒ…å«ä¸€å€‹æˆ–å¤šå€‹å®¹å™¨ã€‚Deployment ç®¡ç† Pod çš„å‰¯æœ¬å’Œæ›´æ–°ç­–ç•¥ã€‚Service æä¾›ç©©å®šçš„ç¶²è·¯ç«¯é»ã€‚ConfigMap å­˜å„²é…ç½®æ•¸æ“šï¼ŒSecret å­˜å„²æ•æ„Ÿè³‡è¨Šã€‚æŒæ¡é€™äº›åŸºç¤æ¦‚å¿µå¾Œï¼Œä½ å°±å¯ä»¥é–‹å§‹å¯¦éš›éƒ¨ç½²äº†ã€‚"
        },
        {
            "role": "user",
            "content": "é‚£éº¼ GitOps åœ¨é€™è£¡æ‰®æ¼”ä»€éº¼è§’è‰²ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "GitOps æ˜¯ä¸€ç¨®ä½¿ç”¨ Git ä½œç‚ºå–®ä¸€çœŸå¯¦ä¾†æºçš„é‹ç¶­å¯¦è¸ã€‚å› ç‚ºæ‰€æœ‰çš„é…ç½®éƒ½å­˜å„²åœ¨ Git å€‰åº«ä¸­ï¼Œæ‰€ä»¥å¯ä»¥è¿½è¹¤æ¯æ¬¡è®Šæ›´çš„æ­·å²ã€‚ç•¶é…ç½®è¢«æ¨é€åˆ° Git å¾Œï¼Œè‡ªå‹•åŒ–å·¥å…·ï¼ˆå¦‚ Argo CDï¼‰æœƒæª¢æ¸¬è®Šæ›´ä¸¦åŒæ­¥åˆ°é›†ç¾¤ã€‚å› æ­¤ï¼Œé€™ç¨®æ–¹å¼æä¾›äº†æ›´å¥½çš„å¯å¯©è¨ˆæ€§å’Œå›æ»¾èƒ½åŠ›ã€‚"
        },
        {
            "role": "user",
            "content": "è½èµ·ä¾†å¾ˆè¤‡é›œï¼Œæœ‰ä»€éº¼æœ€ä½³å¯¦è¸å—ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "æœ€ä½³å¯¦è¸åŒ…æ‹¬ï¼š1) ä½¿ç”¨å‘½åç©ºé–“éš”é›¢ä¸åŒç’°å¢ƒï¼›2) è¨­ç½®è³‡æºé™åˆ¶å’Œè«‹æ±‚ï¼›3) ä½¿ç”¨ Health Check ç¢ºä¿æœå‹™å¯ç”¨æ€§ï¼›4) å¯¦æ–½æ»¾å‹•æ›´æ–°ç­–ç•¥ï¼›5) å»ºç«‹å®Œå–„çš„ç›£æ§å’Œæ—¥èªŒç³»çµ±ã€‚ç¸½ä¹‹ï¼Œå¾å°è¦æ¨¡é–‹å§‹ï¼Œé€æ­¥æ“´å±•æ˜¯æœ€ç©©å¦¥çš„æ–¹æ³•ã€‚"
        }
    ]
    
    extractor = ConversationExtractor()
    
    # åŸ·è¡Œæ³¨æ„åŠ›åˆ†æ
    attention = extractor.analyze_attention(conversation)
    
    print(f"\nğŸ“Š åˆ†æçµæœ:")
    print(f"  - é—œéµæ™‚åˆ»: {len(attention['key_moments'])} å€‹")
    print(f"  - è©±é¡Œè½‰æ›: {len(attention['topic_shifts'])} å€‹")
    print(f"  - è³‡è¨Šå¯†é›†æ®µè½: {len(attention['high_density_segments'])} å€‹")
    
    if attention['key_moments']:
        print(f"\nğŸ’¡ é—œéµæ™‚åˆ»ç¯„ä¾‹:")
        for i, moment in enumerate(attention['key_moments'][:2], 1):
            print(f"  {i}. å•é¡Œ: {moment['question'][:60]}...")
    
    if attention['topic_shifts']:
        print(f"\nğŸ”„ è©±é¡Œè½‰æ›ç¯„ä¾‹:")
        for i, shift in enumerate(attention['topic_shifts'][:2], 1):
            print(f"  {i}. å¾ {shift['from_topics'][:2]} â†’ {shift['to_topics'][:2]}")


def demo_logical_structure():
    """é‚è¼¯çµæ§‹æå–ç¤ºç¯„"""
    print("\n" + "=" * 60)
    print("ğŸ§¬ ç¤ºç¯„ 3ï¼šé‚è¼¯çµæ§‹æå–")
    print("=" * 60)
    
    conversation = [
        {
            "role": "user",
            "content": "ç‚ºä»€éº¼ç³»çµ±éœ€è¦è¨˜æ†¶å°å­˜æ©Ÿåˆ¶ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "è¨˜æ†¶å°å­˜æ©Ÿåˆ¶çš„æ ¸å¿ƒåƒ¹å€¼åœ¨æ–¼ç‹€æ…‹ä¿å­˜å’Œæ¢å¾©ã€‚å› ç‚º AI ç³»çµ±çš„é‹è¡Œç‹€æ…‹åŒ…å«å¤§é‡ä¸Šä¸‹æ–‡è³‡è¨Šï¼Œæ‰€ä»¥éœ€è¦ä¸€å€‹æœ‰æ•ˆçš„æ–¹å¼ä¾†æŒä¹…åŒ–é€™äº›è³‡è¨Šã€‚å¾æŠ€è¡“è§’åº¦çœ‹ï¼Œè¨˜æ†¶å°å­˜å¯¦ç¾äº†ç‹€æ…‹çš„å¿«ç…§ã€å£“ç¸®å’Œå‚³è¼¸ã€‚å› æ­¤ï¼Œç³»çµ±å¯ä»¥åœ¨ä¸åŒç’°å¢ƒé–“é·ç§»ï¼Œæˆ–åœ¨å¤±æ•—å¾Œå¿«é€Ÿæ¢å¾©ã€‚"
        },
        {
            "role": "user",
            "content": "é€™å’Œå‚³çµ±çš„è³‡æ–™åº«å‚™ä»½æœ‰ä»€éº¼å€åˆ¥ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "å‚³çµ±å‚™ä»½é—œæ³¨æ•¸æ“šå®Œæ•´æ€§ï¼Œè€Œè¨˜æ†¶å°å­˜é—œæ³¨é‚è¼¯é€£çºŒæ€§ã€‚ç”±æ–¼ AI ç³»çµ±çš„ç‹€æ…‹ä¸åƒ…åŒ…æ‹¬æ•¸æ“šï¼Œé‚„åŒ…æ‹¬æ¨ç†éç¨‹å’Œä¸Šä¸‹æ–‡é—œä¿‚ï¼Œå› æ­¤éœ€è¦æ›´è±å¯Œçš„å…ƒæ•¸æ“šä¾†æè¿°é€™äº›ç‹€æ…‹ã€‚ç¸½ä¹‹ï¼Œè¨˜æ†¶å°å­˜æ˜¯ä¸€ç¨®æ›´é«˜å±¤æ¬¡çš„æŠ½è±¡ï¼Œé©åˆ AI ç³»çµ±çš„ç‰¹æ€§ã€‚"
        }
    ]
    
    extractor = ConversationExtractor()
    
    # æå–é‚è¼¯çµæ§‹
    structure = extractor.extract_logical_structure(conversation)
    
    print(f"\nğŸ“‹ çµæ§‹åˆ†æçµæœ:")
    print(f"  - æ ¸å¿ƒæ¦‚å¿µ: {len(structure['concepts'])} å€‹")
    print(f"  - å› æœé—œä¿‚: {len(structure['relationships'])} å€‹")
    print(f"  - æ¨ç†éˆ: {len(structure['reasoning_chains'])} æ¢")
    print(f"  - çµè«–: {len(structure['conclusions'])} å€‹")
    
    if structure['concepts']:
        print(f"\nğŸ”‘ æ ¸å¿ƒæ¦‚å¿µç¯„ä¾‹:")
        for concept in structure['concepts'][:5]:
            print(f"  â€¢ {concept}")
    
    if structure['relationships']:
        print(f"\nâš¡ å› æœé—œä¿‚ç¯„ä¾‹:")
        for i, rel in enumerate(structure['relationships'][:2], 1):
            print(f"  {i}. åŸå› : {rel['cause'][:40]}...")
            print(f"     çµæœ: {rel['effect'][:40]}...")


def demo_report_generation():
    """å ±å‘Šç”Ÿæˆç¤ºç¯„"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ç¤ºç¯„ 4ï¼šå®Œæ•´å ±å‘Šç”Ÿæˆ")
    print("=" * 60)
    
    conversation = [
        {
            "role": "user",
            "content": "FlowAgent ç³»çµ±çš„æ ¸å¿ƒç†å¿µæ˜¯ä»€éº¼ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "FlowAgent çš„æ ¸å¿ƒç†å¿µæ˜¯ã€Œå…±æŒ¯å¼å”åŒã€ã€‚ç³»çµ±é€šéäººæ ¼åŒ–çš„ AI ä»£ç†å¯¦ç¾ä»»å‹™åˆ†è§£å’ŒåŸ·è¡Œã€‚æ¯å€‹ä»£ç†éƒ½æœ‰ç¨ç‰¹çš„å…±æŒ¯éµï¼Œç”¨æ–¼è­˜åˆ¥å’Œé€£æ¥ã€‚å› æ­¤ï¼Œå¤šå€‹ä»£ç†å¯ä»¥å”åŒå·¥ä½œï¼Œå½¢æˆä¸€å€‹æœ‰æ©Ÿçš„è¨ˆç®—ç”Ÿæ…‹ç³»çµ±ã€‚"
        },
        {
            "role": "user",
            "content": "é€™ç¨®è¨­è¨ˆæœ‰ä»€éº¼å„ªå‹¢ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "ä¸»è¦å„ªå‹¢åŒ…æ‹¬ï¼šé«˜åº¦æ¨¡çµ„åŒ–ã€æ˜“æ–¼æ“´å±•ã€è‡ªç„¶èªè¨€äº¤äº’å’Œè·¨é ˜åŸŸé©æ‡‰ã€‚ç”±æ–¼æ¯å€‹ä»£ç†éƒ½æ˜¯ç¨ç«‹çš„ï¼Œæ‰€ä»¥ç³»çµ±å…·æœ‰å¾ˆå¥½çš„å®¹éŒ¯æ€§ã€‚ç¸½ä¹‹ï¼Œé€™ç¨®è¨­è¨ˆä½¿å¾— AI ç³»çµ±æ›´åŠ éˆæ´»å’Œæ™ºæ…§ã€‚"
        }
    ]
    
    extractor = ConversationExtractor()
    
    # ç”Ÿæˆå ±å‘Šï¼ˆä¸åŒ…å« AI åˆ†æï¼Œå› ç‚ºæ²’æœ‰ API keyï¼‰
    report = extractor.generate_report(conversation, include_ai_analysis=False)
    
    print("\nâœ“ å ±å‘Šå·²ç”Ÿæˆ")
    print("\n--- å ±å‘Šé è¦½ (å‰ 500 å­—ç¬¦) ---")
    print(report[:500])
    print("...\n")
    
    # ä¿å­˜å ±å‘Š
    os.makedirs("/tmp/conversation_demo", exist_ok=True)
    report_path = "/tmp/conversation_demo/analysis_report.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)
    
    print(f"âœ“ å®Œæ•´å ±å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def main():
    """ä¸»ç¨‹åº"""
    print("\n" + "ğŸ§  å°è©±çŸ¥è­˜æå–å™¨ v1.0 - ç¤ºç¯„ç¨‹åº")
    print("=" * 60)
    print("ä½œè€…: MR.liou Ã— Claude (empathetic.mirror)")
    print("=" * 60)
    
    try:
        demo_basic_usage()
        demo_attention_analysis()
        demo_logical_structure()
        demo_report_generation()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ç¤ºç¯„å®Œæˆï¼")
        print("=" * 60)
        print("\nğŸ“ è¼¸å‡ºæª”æ¡ˆä½ç½®: /tmp/conversation_demo/")
        print("  - demo.json (JSON æ ¼å¼)")
        print("  - demo.md (Markdown æ ¼å¼)")
        print("  - demo.txt (ç´”æ–‡å­—æ ¼å¼)")
        print("  - analysis_report.md (åˆ†æå ±å‘Š)")
        
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
