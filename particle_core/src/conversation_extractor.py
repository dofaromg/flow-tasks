"""
å°è©±çŸ¥è­˜æå–å™¨ - Conversation Knowledge Extractor
ä½œè€…: MR.liou Ã— Claude (empathetic.mirror)
ç‰ˆæœ¬: v1.0

åŠŸèƒ½:
1. å°è©±æ‰“åŒ…èˆ‡å°å‡º
2. æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æï¼ˆè­˜åˆ¥é‡é»ï¼‰
3. é‚è¼¯çµæ§‹æå–
4. çŸ¥è­˜åœ–è­œç”Ÿæˆ
5. æ¦‚å¿µé—œè¯åˆ†æ
"""

import json
import re
import csv
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from collections import Counter, defaultdict
from html import escape as html_escape

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    import yaml
    YAML_AVAILABLE = True
except ImportError:
    YAML_AVAILABLE = False


class ConversationExtractor:
    """å°è©±çŸ¥è­˜æå–å™¨æ ¸å¿ƒé¡åˆ¥"""
    
    # é å®šç¾©èª¿è‰²ç›¤ä¸»é¡Œ
    COLOR_PALETTES = {
        "default": {
            "name": "é è¨­ (Default)",
            "bg_body": "#f5f5f5",
            "bg_container": "white",
            "bg_metadata": "#f8f9fa",
            "bg_user": "#e3f2fd",
            "bg_assistant": "#f3e5f5",
            "bg_stats": "#fff3e0",
            "border_title": "#4CAF50",
            "border_user": "#2196F3",
            "border_assistant": "#9C27B0",
            "text_primary": "#333",
            "text_secondary": "#555"
        },
        "ocean": {
            "name": "æµ·æ´‹ (Ocean)",
            "bg_body": "#e0f7fa",
            "bg_container": "white",
            "bg_metadata": "#b2ebf2",
            "bg_user": "#b2dfdb",
            "bg_assistant": "#c8e6c9",
            "bg_stats": "#fff9c4",
            "border_title": "#00796b",
            "border_user": "#00897b",
            "border_assistant": "#388e3c",
            "text_primary": "#004d40",
            "text_secondary": "#00695c"
        },
        "sunset": {
            "name": "æ—¥è½ (Sunset)",
            "bg_body": "#ffe0b2",
            "bg_container": "white",
            "bg_metadata": "#ffccbc",
            "bg_user": "#ffecb3",
            "bg_assistant": "#ffe0b2",
            "bg_stats": "#f8bbd0",
            "border_title": "#d84315",
            "border_user": "#f57c00",
            "border_assistant": "#e64a19",
            "text_primary": "#bf360c",
            "text_secondary": "#d84315"
        },
        "night": {
            "name": "å¤œæ™š (Night)",
            "bg_body": "#263238",
            "bg_container": "#37474f",
            "bg_metadata": "#455a64",
            "bg_user": "#546e7a",
            "bg_assistant": "#607d8b",
            "bg_stats": "#78909c",
            "border_title": "#00bcd4",
            "border_user": "#03a9f4",
            "border_assistant": "#00acc1",
            "text_primary": "#eceff1",
            "text_secondary": "#cfd8dc"
        },
        "forest": {
            "name": "æ£®æ— (Forest)",
            "bg_body": "#e8f5e9",
            "bg_container": "white",
            "bg_metadata": "#c8e6c9",
            "bg_user": "#a5d6a7",
            "bg_assistant": "#c5e1a5",
            "bg_stats": "#f0f4c3",
            "border_title": "#2e7d32",
            "border_user": "#388e3c",
            "border_assistant": "#558b2f",
            "text_primary": "#1b5e20",
            "text_secondary": "#2e7d32"
        },
        "minimal": {
            "name": "æ¥µç°¡ (Minimal)",
            "bg_body": "#ffffff",
            "bg_container": "#fafafa",
            "bg_metadata": "#f5f5f5",
            "bg_user": "#eeeeee",
            "bg_assistant": "#e0e0e0",
            "bg_stats": "#f5f5f5",
            "border_title": "#000000",
            "border_user": "#424242",
            "border_assistant": "#616161",
            "text_primary": "#000000",
            "text_secondary": "#424242"
        }
    }
    
    def __init__(self, api_key: str = None, theme: str = "default"):
        """
        åˆå§‹åŒ–æå–å™¨
        
        Args:
            api_key: Anthropic API Key (ç”¨æ–¼æ·±åº¦åˆ†æ)
            theme: HTML è¼¸å‡ºçš„ä¸»é¡Œèª¿è‰²ç›¤ (default/ocean/sunset/night/forest/minimal)
        """
        self.api_key = api_key
        self.theme = theme if theme in self.COLOR_PALETTES else "default"
        
        if api_key and ANTHROPIC_AVAILABLE:
            self.client = anthropic.Anthropic(api_key=api_key)
        elif api_key and not ANTHROPIC_AVAILABLE:
            print("âš ï¸  Warning: anthropic library not installed. AI analysis will not be available.")
    
    # ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šå°è©±æ‰“åŒ… ====================
    
    def package_conversation(self, messages: List[Dict], metadata: Dict = None) -> Dict:
        """
        æ‰“åŒ…å°è©±è¨˜éŒ„
        
        Args:
            messages: å°è©±åˆ—è¡¨ [{"role": "user/assistant", "content": "..."}]
            metadata: å°è©±å…ƒæ•¸æ“š {"title": "...", "date": "...", "tags": [...]}
        
        Returns:
            æ‰“åŒ…å¥½çš„å°è©±æ•¸æ“š
        """
        package = {
            "metadata": metadata or {},
            "messages": messages,
            "statistics": self._calculate_statistics(messages),
            "exported_at": datetime.now().isoformat(),
            "version": "1.0"
        }
        
        return package
    
    def _calculate_statistics(self, messages: List[Dict]) -> Dict:
        """è¨ˆç®—å°è©±çµ±è¨ˆè³‡è¨Š"""
        user_msgs = [m for m in messages if m["role"] == "user"]
        assistant_msgs = [m for m in messages if m["role"] == "assistant"]
        
        return {
            "total_messages": len(messages),
            "user_messages": len(user_msgs),
            "assistant_messages": len(assistant_msgs),
            "total_chars": sum(len(m["content"]) for m in messages),
            "avg_user_length": sum(len(m["content"]) for m in user_msgs) / len(user_msgs) if user_msgs else 0,
            "avg_assistant_length": sum(len(m["content"]) for m in assistant_msgs) / len(assistant_msgs) if assistant_msgs else 0
        }
    
    def export_to_file(self, package: Dict, filepath: str, format: str = "json"):
        """
        å°å‡ºå°è©±åŒ…åˆ°æª”æ¡ˆ
        
        Args:
            package: å°è©±åŒ…
            filepath: æª”æ¡ˆè·¯å¾‘
            format: æ ¼å¼ (json/markdown/txt/yaml/csv/html/xml)
        """
        if format == "json":
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(package, f, ensure_ascii=False, indent=2)
            print(f"âœ“ å·²å°å‡º JSON: {filepath}")
        
        elif format == "markdown" or format == "md":
            md_content = self._convert_to_markdown(package)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(md_content)
            print(f"âœ“ å·²å°å‡º Markdown: {filepath}")
        
        elif format == "txt" or format == "text":
            txt_content = self._convert_to_text(package)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(txt_content)
            print(f"âœ“ å·²å°å‡º TXT: {filepath}")
        
        elif format == "yaml" or format == "yml":
            yaml_content = self._convert_to_yaml(package)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(yaml_content)
            print(f"âœ“ å·²å°å‡º YAML: {filepath}")
        
        elif format == "csv":
            self._convert_to_csv(package, filepath)
            print(f"âœ“ å·²å°å‡º CSV: {filepath}")
        
        elif format == "html" or format == "htm":
            html_content = self._convert_to_html(package)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
            print(f"âœ“ å·²å°å‡º HTML: {filepath}")
        
        elif format == "xml":
            xml_content = self._convert_to_xml(package)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(xml_content)
            print(f"âœ“ å·²å°å‡º XML: {filepath}")
        
        else:
            print(f"âš ï¸  ä¸æ”¯æ´çš„æ ¼å¼: {format}")
            print(f"   æ”¯æ´çš„æ ¼å¼: json, markdown/md, txt/text, yaml/yml, csv, html/htm, xml")
    
    def export_batch(self, package: Dict, base_path: str, formats: List[str] = None):
        """
        æ‰¹æ¬¡å°å‡ºå¤šç¨®æ ¼å¼
        
        Args:
            package: å°è©±åŒ…
            base_path: åŸºç¤æª”æ¡ˆè·¯å¾‘ï¼ˆä¸å«å‰¯æª”åï¼‰
            formats: è¦å°å‡ºçš„æ ¼å¼åˆ—è¡¨ï¼Œé è¨­ç‚ºæ‰€æœ‰æ ¼å¼
        
        Returns:
            å°å‡ºçš„æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        """
        if formats is None:
            formats = ['json', 'md', 'txt', 'yaml', 'csv', 'html', 'xml']
        
        exported_files = []
        
        print(f"\nğŸ“¦ æ‰¹æ¬¡å°å‡º {len(formats)} ç¨®æ ¼å¼...")
        print("=" * 60)
        
        for fmt in formats:
            # ç¢ºå®šå‰¯æª”å
            if fmt in ['md', 'markdown']:
                ext = 'md'
            elif fmt in ['txt', 'text']:
                ext = 'txt'
            elif fmt in ['yaml', 'yml']:
                ext = 'yaml'
            elif fmt in ['html', 'htm']:
                ext = 'html'
            else:
                ext = fmt
            
            filepath = f"{base_path}.{ext}"
            
            try:
                self.export_to_file(package, filepath, fmt)
                exported_files.append(filepath)
            except Exception as e:
                print(f"âœ— å°å‡º {fmt} å¤±æ•—: {e}")
        
        print("=" * 60)
        print(f"âœ“ æˆåŠŸå°å‡º {len(exported_files)}/{len(formats)} å€‹æª”æ¡ˆ")
        
        return exported_files
    
    def generate_website_bundle(self, package: Dict, output_dir: str, themes: List[str] = None):
        """
        ç”Ÿæˆå®Œæ•´ç¶²ç«™å¥—ä»¶ï¼ˆåŒ…å«å¤šå€‹ä¸»é¡Œçš„ HTML å’Œå…¶ä»–æ ¼å¼ï¼‰
        
        Args:
            package: å°è©±åŒ…
            output_dir: è¼¸å‡ºç›®éŒ„
            themes: è¦ç”Ÿæˆçš„ä¸»é¡Œåˆ—è¡¨ï¼Œé è¨­ç‚ºæ‰€æœ‰ä¸»é¡Œ
        
        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆè³‡è¨Šå­—å…¸
        """
        import os
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(output_dir, exist_ok=True)
        
        if themes is None:
            themes = list(self.COLOR_PALETTES.keys())
        
        print(f"\nğŸŒ ç”Ÿæˆç¶²ç«™å¥—ä»¶...")
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
        print("=" * 60)
        
        generated_files = {
            "html_files": [],
            "data_files": [],
            "index_file": None
        }
        
        # 1. ç”Ÿæˆå¤šå€‹ä¸»é¡Œçš„ HTML æª”æ¡ˆ
        print(f"\nğŸ¨ ç”Ÿæˆ {len(themes)} å€‹ä¸»é¡Œè®ŠåŒ–...")
        for theme in themes:
            # æš«æ™‚åˆ‡æ›ä¸»é¡Œ
            original_theme = self.theme
            self.theme = theme
            
            theme_filename = f"conversation_{theme}.html"
            theme_path = os.path.join(output_dir, theme_filename)
            
            html_content = self._convert_to_html(package)
            with open(theme_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            print(f"  âœ“ {self.COLOR_PALETTES[theme]['name']}: {theme_filename}")
            generated_files["html_files"].append(theme_filename)
            
            # æ¢å¾©åŸä¸»é¡Œ
            self.theme = original_theme
        
        # 2. ç”Ÿæˆæ•¸æ“šæª”æ¡ˆï¼ˆJSON, YAML, CSV, XMLï¼‰
        print(f"\nğŸ“Š ç”Ÿæˆæ•¸æ“šæª”æ¡ˆ...")
        data_formats = [
            ('json', 'conversation.json'),
            ('yaml', 'conversation.yaml'),
            ('csv', 'conversation.csv'),
            ('xml', 'conversation.xml')
        ]
        
        for fmt, filename in data_formats:
            filepath = os.path.join(output_dir, filename)
            self.export_to_file(package, filepath, fmt)
            generated_files["data_files"].append(filename)
        
        # 3. ç”Ÿæˆæ–‡æª”æª”æ¡ˆï¼ˆMarkdown, TXTï¼‰
        print(f"\nğŸ“ ç”Ÿæˆæ–‡æª”æª”æ¡ˆ...")
        doc_formats = [
            ('md', 'conversation.md'),
            ('txt', 'conversation.txt')
        ]
        
        for fmt, filename in doc_formats:
            filepath = os.path.join(output_dir, filename)
            self.export_to_file(package, filepath, fmt)
            generated_files["data_files"].append(filename)
        
        # 4. ç”Ÿæˆç´¢å¼•é é¢ï¼ˆåˆ—å‡ºæ‰€æœ‰ä¸»é¡Œï¼‰
        print(f"\nğŸ“‘ ç”Ÿæˆç´¢å¼•é é¢...")
        index_path = os.path.join(output_dir, "index.html")
        self._generate_index_page(package, index_path, themes)
        generated_files["index_file"] = "index.html"
        
        print("=" * 60)
        print(f"âœ… ç¶²ç«™å¥—ä»¶ç”Ÿæˆå®Œæˆï¼")
        print(f"   â€¢ HTML ä¸»é¡Œ: {len(generated_files['html_files'])} å€‹")
        print(f"   â€¢ æ•¸æ“šæª”æ¡ˆ: {len(generated_files['data_files'])} å€‹")
        print(f"   â€¢ ç´¢å¼•é é¢: 1 å€‹")
        print(f"\nğŸŒ é–‹å•Ÿ {os.path.join(output_dir, 'index.html')} æŸ¥çœ‹å®Œæ•´ç¶²ç«™")
        
        return generated_files
    
    def _generate_index_page(self, package: Dict, filepath: str, themes: List[str]):
        """ç”Ÿæˆç´¢å¼•é é¢ï¼Œåˆ—å‡ºæ‰€æœ‰ä¸»é¡Œè®ŠåŒ–"""
        metadata = package.get("metadata", {})
        title = html_escape(metadata.get('title', 'å°è©±è¨˜éŒ„'))
        
        lines = []
        lines.append("<!DOCTYPE html>")
        lines.append("<html lang=\"zh-TW\">")
        lines.append("<head>")
        lines.append("    <meta charset=\"UTF-8\">")
        lines.append("    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">")
        lines.append(f"    <title>{title} - ä¸»é¡Œç´¢å¼•</title>")
        lines.append("    <style>")
        lines.append("        * { margin: 0; padding: 0; box-sizing: border-box; }")
        lines.append("        body { font-family: 'Microsoft JhengHei', Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 40px 20px; }")
        lines.append("        .container { max-width: 1200px; margin: 0 auto; }")
        lines.append("        h1 { color: white; text-align: center; font-size: 2.5em; margin-bottom: 20px; text-shadow: 2px 2px 4px rgba(0,0,0,0.2); }")
        lines.append("        .subtitle { color: rgba(255,255,255,0.9); text-align: center; font-size: 1.2em; margin-bottom: 40px; }")
        lines.append("        .theme-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 25px; margin-bottom: 40px; }")
        lines.append("        .theme-card { background: white; border-radius: 12px; padding: 25px; box-shadow: 0 4px 15px rgba(0,0,0,0.2); transition: transform 0.3s, box-shadow 0.3s; cursor: pointer; }")
        lines.append("        .theme-card:hover { transform: translateY(-5px); box-shadow: 0 8px 25px rgba(0,0,0,0.3); }")
        lines.append("        .theme-name { font-size: 1.5em; font-weight: bold; margin-bottom: 15px; color: #333; }")
        lines.append("        .theme-preview { height: 80px; border-radius: 8px; margin-bottom: 15px; display: flex; gap: 5px; }")
        lines.append("        .color-bar { flex: 1; border-radius: 4px; }")
        lines.append("        .theme-link { display: inline-block; padding: 10px 20px; background: #667eea; color: white; text-decoration: none; border-radius: 6px; font-weight: bold; transition: background 0.3s; }")
        lines.append("        .theme-link:hover { background: #764ba2; }")
        lines.append("        .data-section { background: white; border-radius: 12px; padding: 30px; box-shadow: 0 4px 15px rgba(0,0,0,0.2); margin-top: 30px; }")
        lines.append("        .data-section h2 { color: #333; margin-bottom: 20px; font-size: 1.8em; }")
        lines.append("        .data-links { display: flex; flex-wrap: wrap; gap: 15px; }")
        lines.append("        .data-link { padding: 12px 24px; background: #f5f5f5; color: #333; text-decoration: none; border-radius: 6px; font-weight: 500; transition: background 0.3s; border: 2px solid #ddd; }")
        lines.append("        .data-link:hover { background: #e0e0e0; border-color: #667eea; }")
        lines.append("    </style>")
        lines.append("</head>")
        lines.append("<body>")
        lines.append("    <div class=\"container\">")
        lines.append(f"        <h1>ğŸ¨ {title}</h1>")
        lines.append(f"        <p class=\"subtitle\">é¸æ“‡æ‚¨å–œæ­¡çš„ä¸»é¡Œæ¨£å¼ï¼Œæˆ–ä¸‹è¼‰æ•¸æ“šæª”æ¡ˆ</p>")
        lines.append("        <div class=\"theme-grid\">")
        
        # ç‚ºæ¯å€‹ä¸»é¡Œå‰µå»ºå¡ç‰‡
        for theme in themes:
            palette = self.COLOR_PALETTES[theme]
            lines.append("            <div class=\"theme-card\">")
            lines.append(f"                <div class=\"theme-name\">{palette['name']}</div>")
            lines.append("                <div class=\"theme-preview\">")
            lines.append(f"                    <div class=\"color-bar\" style=\"background: {palette['bg_user']};\"></div>")
            lines.append(f"                    <div class=\"color-bar\" style=\"background: {palette['border_user']};\"></div>")
            lines.append(f"                    <div class=\"color-bar\" style=\"background: {palette['bg_assistant']};\"></div>")
            lines.append(f"                    <div class=\"color-bar\" style=\"background: {palette['border_assistant']};\"></div>")
            lines.append(f"                    <div class=\"color-bar\" style=\"background: {palette['border_title']};\"></div>")
            lines.append("                </div>")
            lines.append(f"                <a href=\"conversation_{theme}.html\" class=\"theme-link\">æŸ¥çœ‹ â†’</a>")
            lines.append("            </div>")
        
        lines.append("        </div>")
        
        # æ•¸æ“šæª”æ¡ˆä¸‹è¼‰å€
        lines.append("        <div class=\"data-section\">")
        lines.append("            <h2>ğŸ“Š ä¸‹è¼‰æ•¸æ“šæª”æ¡ˆ</h2>")
        lines.append("            <div class=\"data-links\">")
        lines.append("                <a href=\"conversation.json\" class=\"data-link\" download>ğŸ“„ JSON</a>")
        lines.append("                <a href=\"conversation.yaml\" class=\"data-link\" download>ğŸ“‹ YAML</a>")
        lines.append("                <a href=\"conversation.csv\" class=\"data-link\" download>ğŸ“Š CSV</a>")
        lines.append("                <a href=\"conversation.xml\" class=\"data-link\" download>ğŸ“ XML</a>")
        lines.append("                <a href=\"conversation.md\" class=\"data-link\" download>ğŸ“– Markdown</a>")
        lines.append("                <a href=\"conversation.txt\" class=\"data-link\" download>ğŸ“ƒ TXT</a>")
        lines.append("            </div>")
        lines.append("        </div>")
        
        lines.append("    </div>")
        lines.append("</body>")
        lines.append("</html>")
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
        
        print(f"  âœ“ index.html")
    
    def _convert_to_markdown(self, package: Dict) -> str:
        """è½‰æ›ç‚º Markdown æ ¼å¼"""
        lines = []
        
        # æ¨™é¡Œèˆ‡å…ƒæ•¸æ“š
        metadata = package.get("metadata", {})
        lines.append(f"# {metadata.get('title', 'å°è©±è¨˜éŒ„')}\n")
        lines.append(f"**æ—¥æœŸ**: {metadata.get('date', 'N/A')}\n")
        lines.append(f"**æ¨™ç±¤**: {', '.join(metadata.get('tags', []))}\n")
        lines.append("\n---\n\n")
        
        # å°è©±å…§å®¹
        for msg in package["messages"]:
            role = "ğŸ‘¤ User" if msg["role"] == "user" else "ğŸ¤– Assistant"
            lines.append(f"### {role}\n\n")
            lines.append(f"{msg['content']}\n\n")
            lines.append("---\n\n")
        
        return "".join(lines)
    
    def _convert_to_text(self, package: Dict) -> str:
        """è½‰æ›ç‚ºç´”æ–‡å­—æ ¼å¼"""
        lines = []
        
        for msg in package["messages"]:
            role = "USER" if msg["role"] == "user" else "ASSISTANT"
            lines.append(f"[{role}]")
            lines.append(msg["content"])
            lines.append("\n" + "="*50 + "\n")
        
        return "\n".join(lines)
    
    def _convert_to_yaml(self, package: Dict) -> str:
        """è½‰æ›ç‚º YAML æ ¼å¼"""
        if not YAML_AVAILABLE:
            # Fallback to manual YAML generation if pyyaml not available
            def escape_yaml_string(s):
                """Properly escape YAML string content"""
                # Replace backslashes first to avoid double-escaping
                s = s.replace('\\', '\\\\')
                s = s.replace('"', '\\"')
                s = s.replace('\n', '\\n')
                s = s.replace('\r', '\\r')
                s = s.replace('\t', '\\t')
                return s
            
            lines = []
            lines.append("---")
            lines.append("metadata:")
            metadata = package.get("metadata", {})
            lines.append(f"  title: \"{escape_yaml_string(metadata.get('title', 'å°è©±è¨˜éŒ„'))}\"")
            lines.append(f"  date: \"{escape_yaml_string(metadata.get('date', 'N/A'))}\"")
            tags = metadata.get('tags', [])
            if tags:
                lines.append("  tags:")
                for tag in tags:
                    lines.append(f"    - \"{escape_yaml_string(str(tag))}\"")
            
            lines.append("\nmessages:")
            for i, msg in enumerate(package["messages"]):
                lines.append(f"  - index: {i}")
                lines.append(f"    role: \"{msg['role']}\"")
                # Escape content properly
                content = escape_yaml_string(msg['content'])
                lines.append(f"    content: \"{content}\"")
            
            lines.append("\nstatistics:")
            stats = package.get("statistics", {})
            for key, value in stats.items():
                lines.append(f"  {key}: {value}")
            
            lines.append(f"\nexported_at: \"{package.get('exported_at', '')}\"")
            lines.append(f"version: \"{package.get('version', '1.0')}\"")
            
            return "\n".join(lines)
        else:
            return yaml.dump(package, allow_unicode=True, default_flow_style=False, sort_keys=False)
    
    def _convert_to_csv(self, package: Dict, filepath: str):
        """è½‰æ›ç‚º CSV æ ¼å¼"""
        with open(filepath, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            
            # Write headers
            writer.writerow(['Index', 'Role', 'Content', 'Length'])
            
            # Write conversation messages
            for i, msg in enumerate(package["messages"]):
                writer.writerow([
                    i,
                    msg["role"],
                    msg["content"],
                    len(msg["content"])
                ])
    
    def _convert_to_html(self, package: Dict, custom_palette: Dict = None) -> str:
        """
        è½‰æ›ç‚º HTML æ ¼å¼
        
        Args:
            package: å°è©±åŒ…
            custom_palette: è‡ªå®šç¾©èª¿è‰²ç›¤ï¼ˆå¯é¸ï¼‰
        """
        lines = []
        
        # é¸æ“‡èª¿è‰²ç›¤
        if custom_palette:
            palette = custom_palette
        else:
            palette = self.COLOR_PALETTES.get(self.theme, self.COLOR_PALETTES["default"])
        
        # HTML header
        lines.append("<!DOCTYPE html>")
        lines.append("<html lang=\"zh-TW\">")
        lines.append("<head>")
        lines.append("    <meta charset=\"UTF-8\">")
        lines.append("    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">")
        
        metadata = package.get("metadata", {})
        title = html_escape(metadata.get('title', 'å°è©±è¨˜éŒ„'))
        lines.append(f"    <title>{title}</title>")
        
        # Add CSS styling with theme colors
        lines.append("    <style>")
        lines.append(f"        body {{ font-family: 'Microsoft JhengHei', Arial, sans-serif; max-width: 900px; margin: 40px auto; padding: 20px; background: {palette['bg_body']}; }}")
        lines.append(f"        .container {{ background: {palette['bg_container']}; padding: 30px; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}")
        lines.append(f"        h1 {{ color: {palette['text_primary']}; border-bottom: 3px solid {palette['border_title']}; padding-bottom: 10px; }}")
        lines.append(f"        .metadata {{ background: {palette['bg_metadata']}; padding: 15px; border-radius: 5px; margin-bottom: 30px; color: {palette['text_primary']}; }}")
        lines.append(f"        .message {{ margin: 20px 0; padding: 15px; border-radius: 8px; }}")
        lines.append(f"        .user {{ background: {palette['bg_user']}; border-left: 4px solid {palette['border_user']}; }}")
        lines.append(f"        .assistant {{ background: {palette['bg_assistant']}; border-left: 4px solid {palette['border_assistant']}; }}")
        lines.append(f"        .role {{ font-weight: bold; margin-bottom: 10px; color: {palette['text_secondary']}; }}")
        lines.append(f"        .content {{ line-height: 1.6; white-space: pre-wrap; color: {palette['text_primary']}; }}")
        lines.append(f"        .stats {{ margin-top: 30px; padding: 15px; background: {palette['bg_stats']}; border-radius: 5px; color: {palette['text_primary']}; }}")
        lines.append("    </style>")
        lines.append("</head>")
        lines.append("<body>")
        lines.append("    <div class=\"container\">")
        
        # Title and metadata
        lines.append(f"        <h1>{title}</h1>")
        lines.append("        <div class=\"metadata\">")
        lines.append(f"            <p><strong>æ—¥æœŸ:</strong> {html_escape(metadata.get('date', 'N/A'))}</p>")
        tags = metadata.get('tags', [])
        if tags:
            lines.append(f"            <p><strong>æ¨™ç±¤:</strong> {', '.join(html_escape(str(tag)) for tag in tags)}</p>")
        lines.append("        </div>")
        
        # Messages
        for msg in package["messages"]:
            role_class = "user" if msg["role"] == "user" else "assistant"
            role_display = "ğŸ‘¤ ä½¿ç”¨è€…" if msg["role"] == "user" else "ğŸ¤– åŠ©æ‰‹"
            lines.append(f"        <div class=\"message {role_class}\">")
            lines.append(f"            <div class=\"role\">{role_display}</div>")
            lines.append(f"            <div class=\"content\">{html_escape(msg['content'])}</div>")
            lines.append("        </div>")
        
        # Statistics
        stats = package.get("statistics", {})
        if stats:
            lines.append("        <div class=\"stats\">")
            lines.append("            <h3>çµ±è¨ˆè³‡è¨Š</h3>")
            lines.append(f"            <p>ç¸½è¨Šæ¯æ•¸: {stats.get('total_messages', 0)}</p>")
            lines.append(f"            <p>ç”¨æˆ¶è¨Šæ¯: {stats.get('user_messages', 0)}</p>")
            lines.append(f"            <p>åŠ©æ‰‹è¨Šæ¯: {stats.get('assistant_messages', 0)}</p>")
            lines.append(f"            <p>ç¸½å­—ç¬¦æ•¸: {stats.get('total_chars', 0):,}</p>")
            lines.append("        </div>")
        
        lines.append("    </div>")
        lines.append("</body>")
        lines.append("</html>")
        
        return "\n".join(lines)
    
    def _convert_to_xml(self, package: Dict) -> str:
        """è½‰æ›ç‚º XML æ ¼å¼"""
        root = ET.Element("conversation")
        root.set("version", package.get("version", "1.0"))
        root.set("exported_at", package.get("exported_at", ""))
        
        # Metadata
        metadata = package.get("metadata", {})
        meta_elem = ET.SubElement(root, "metadata")
        
        title_elem = ET.SubElement(meta_elem, "title")
        title_elem.text = metadata.get('title', 'å°è©±è¨˜éŒ„')
        
        date_elem = ET.SubElement(meta_elem, "date")
        date_elem.text = metadata.get('date', 'N/A')
        
        tags = metadata.get('tags', [])
        if tags:
            tags_elem = ET.SubElement(meta_elem, "tags")
            for tag in tags:
                tag_elem = ET.SubElement(tags_elem, "tag")
                tag_elem.text = str(tag)
        
        # Messages
        messages_elem = ET.SubElement(root, "messages")
        for i, msg in enumerate(package["messages"]):
            msg_elem = ET.SubElement(messages_elem, "message")
            msg_elem.set("index", str(i))
            
            role_elem = ET.SubElement(msg_elem, "role")
            role_elem.text = msg["role"]
            
            content_elem = ET.SubElement(msg_elem, "content")
            content_elem.text = msg["content"]
        
        # Statistics
        stats = package.get("statistics", {})
        if stats:
            stats_elem = ET.SubElement(root, "statistics")
            for key, value in stats.items():
                stat_elem = ET.SubElement(stats_elem, key)
                stat_elem.text = str(value)
        
        # Convert to string with proper formatting using minidom for pretty printing
        xml_str = ET.tostring(root, encoding='unicode', method='xml')
        
        # Pretty print XML using minidom
        try:
            import xml.dom.minidom as minidom
            dom = minidom.parseString(xml_str)
            # Pretty print with 2-space indentation
            pretty_xml = dom.toprettyxml(indent="  ", encoding=None)
            # Remove extra blank lines
            lines = [line for line in pretty_xml.split('\n') if line.strip()]
            return '\n'.join(lines)
        except:
            # Fallback to basic formatting if minidom fails
            return '<?xml version="1.0" encoding="UTF-8"?>\n' + xml_str
    
    # ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šæ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æ ====================
    
    def analyze_attention(self, messages: List[Dict]) -> Dict:
        """
        ä½¿ç”¨æ³¨æ„åŠ›æ©Ÿåˆ¶è­˜åˆ¥å°è©±é‡é»
        
        Returns:
            {
                "key_moments": [...],  # é—œéµæ™‚åˆ»
                "topic_shifts": [...],  # è©±é¡Œè½‰æ›é»
                "high_density_segments": [...]  # è³‡è¨Šå¯†é›†æ®µè½
            }
        """
        analysis = {
            "key_moments": [],
            "topic_shifts": [],
            "high_density_segments": []
        }
        
        # 1. è­˜åˆ¥é—œéµè©å¯†åº¦
        for i, msg in enumerate(messages):
            keywords = self._extract_keywords(msg["content"])
            
            if len(keywords) > 5:  # è³‡è¨Šå¯†é›†
                analysis["high_density_segments"].append({
                    "index": i,
                    "role": msg["role"],
                    "keywords": keywords[:10],
                    "preview": msg["content"][:100] + "..."
                })
        
        # 2. è­˜åˆ¥è©±é¡Œè½‰æ›
        for i in range(1, len(messages)):
            prev_keywords = set(self._extract_keywords(messages[i-1]["content"]))
            curr_keywords = set(self._extract_keywords(messages[i]["content"]))
            
            overlap = len(prev_keywords & curr_keywords)
            if overlap < 2 and len(curr_keywords) > 3:  # è©±é¡Œå¤§å¹…è½‰æ›
                analysis["topic_shifts"].append({
                    "index": i,
                    "from_topics": list(prev_keywords)[:5],
                    "to_topics": list(curr_keywords)[:5]
                })
        
        # 3. è­˜åˆ¥é—œéµå•ç­”å°
        for i in range(len(messages) - 1):
            if messages[i]["role"] == "user" and "?" in messages[i]["content"]:
                if len(messages[i+1]["content"]) > 200:  # è©³ç´°å›ç­”
                    analysis["key_moments"].append({
                        "index": i,
                        "question": messages[i]["content"][:150],
                        "answer_preview": messages[i+1]["content"][:150]
                    })
        
        return analysis
    
    def _extract_keywords(self, text: str, top_n: int = 10) -> List[str]:
        """æå–é—œéµè©ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # ç§»é™¤æ¨™é»ï¼Œè½‰å°å¯«
        words = re.findall(r'\b\w+\b', text.lower())
        
        # éæ¿¾åœç”¨è©ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        stopwords = {'the', 'is', 'at', 'which', 'on', 'a', 'an', 'and', 'or', 
                     'but', 'in', 'with', 'to', 'for', 'of', 'çš„', 'äº†', 'æ˜¯',
                     'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'é€™', 'é‚£', 'æœ‰', 'å€‹'}
        
        words = [w for w in words if w not in stopwords and len(w) > 2]
        
        # çµ±è¨ˆè©é »
        counter = Counter(words)
        return [word for word, count in counter.most_common(top_n)]
    
    # ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šé‚è¼¯çµæ§‹æå– ====================
    
    def extract_logical_structure(self, messages: List[Dict]) -> Dict:
        """
        æå–å°è©±ä¸­çš„é‚è¼¯çµæ§‹
        
        Returns:
            {
                "concepts": [...],           # æ ¸å¿ƒæ¦‚å¿µ
                "relationships": [...],      # æ¦‚å¿µé—œä¿‚
                "reasoning_chains": [...],   # æ¨ç†éˆ
                "conclusions": [...]         # çµè«–
            }
        """
        structure = {
            "concepts": [],
            "relationships": [],
            "reasoning_chains": [],
            "conclusions": []
        }
        
        # 1. æå–æ ¸å¿ƒæ¦‚å¿µï¼ˆåè©çŸ­èªï¼‰
        all_text = " ".join([m["content"] for m in messages])
        concepts = self._extract_concepts(all_text)
        structure["concepts"] = concepts
        
        # 2. è­˜åˆ¥å› æœé—œä¿‚
        for msg in messages:
            relations = self._extract_causal_relations(msg["content"])
            structure["relationships"].extend(relations)
        
        # 3. è­˜åˆ¥æ¨ç†éˆï¼ˆåŒ…å«ã€Œå› ç‚ºã€ã€Œæ‰€ä»¥ã€ã€Œå› æ­¤ã€ç­‰ï¼‰
        for msg in messages:
            chains = self._extract_reasoning_chains(msg["content"])
            structure["reasoning_chains"].extend(chains)
        
        # 4. æå–çµè«–æ€§èªå¥
        for msg in messages:
            if msg["role"] == "assistant":
                conclusions = self._extract_conclusions(msg["content"])
                structure["conclusions"].extend(conclusions)
        
        return structure
    
    def _extract_concepts(self, text: str) -> List[str]:
        """æå–æ ¸å¿ƒæ¦‚å¿µï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        # è­˜åˆ¥å¤§å¯«é–‹é ­çš„è©çµ„ï¼ˆå¯èƒ½æ˜¯å°ˆæœ‰åè©ï¼‰
        concepts = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        
        # è­˜åˆ¥ä¸­æ–‡å°ˆæœ‰åè©æ¨¡å¼
        chinese_concepts = re.findall(r'[\u4e00-\u9fff]{2,6}(?:ç³»çµ±|ç†è«–|æ¨¡å‹|æ©Ÿåˆ¶|æ–¹æ³•|æ¶æ§‹)', text)
        
        all_concepts = list(set(concepts + chinese_concepts))
        return all_concepts[:20]  # å–å‰ 20 å€‹
    
    def _extract_causal_relations(self, text: str) -> List[Dict]:
        """æå–å› æœé—œä¿‚"""
        relations = []
        
        # åŒ¹é…ã€Œå› ç‚º...æ‰€ä»¥...ã€æ¨¡å¼
        patterns = [
            r'å› ç‚º(.{5,50})æ‰€ä»¥(.{5,50})',
            r'ç”±æ–¼(.{5,50})å› æ­¤(.{5,50})',
            r'(.{5,50})å°è‡´(.{5,50})',
            r'if (.{5,50}) then (.{5,50})',
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                relations.append({
                    "cause": match.group(1).strip(),
                    "effect": match.group(2).strip(),
                    "type": "causal"
                })
        
        return relations
    
    def _extract_reasoning_chains(self, text: str) -> List[List[str]]:
        """æå–æ¨ç†éˆ"""
        chains = []
        
        # åˆ†å‰²æˆå¥å­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
        
        # è­˜åˆ¥åŒ…å«é‚è¼¯é€£æ¥è©çš„å¥å­åºåˆ—
        logic_markers = ['å› æ­¤', 'æ‰€ä»¥', 'å› è€Œ', 'å¾è€Œ', 'é€²è€Œ', 'therefore', 'thus', 'hence']
        
        current_chain = []
        for sent in sentences:
            sent = sent.strip()
            if not sent:
                continue
            
            has_marker = any(marker in sent for marker in logic_markers)
            
            if has_marker or current_chain:
                current_chain.append(sent)
                
                if has_marker and len(current_chain) >= 2:
                    chains.append(current_chain[:])
                    current_chain = []
            
            if len(current_chain) > 5:  # éˆå¤ªé•·ï¼Œé‡ç½®
                current_chain = []
        
        return chains
    
    def _extract_conclusions(self, text: str) -> List[str]:
        """æå–çµè«–æ€§èªå¥"""
        conclusions = []
        
        # çµè«–æ€§æ¨™è¨˜è©
        markers = ['ç¸½ä¹‹', 'ç¶œä¸Šæ‰€è¿°', 'å› æ­¤å¯ä»¥å¾—å‡º', 'çµè«–æ˜¯', 'in conclusion', 
                   'to summarize', 'therefore', 'ç”±æ­¤å¯è¦‹', 'å¯ä»¥çœ‹å‡º']
        
        sentences = re.split(r'[ã€‚ï¼\n]', text)
        
        for sent in sentences:
            if any(marker in sent for marker in markers):
                conclusions.append(sent.strip())
        
        return conclusions
    
    # ==================== ç¬¬å››éƒ¨åˆ†ï¼šAI æ·±åº¦åˆ†æï¼ˆéœ€è¦ API Keyï¼‰====================
    
    def deep_analysis_with_ai(self, messages: List[Dict]) -> Dict:
        """
        ä½¿ç”¨ Claude API é€²è¡Œæ·±åº¦åˆ†æ
        
        Returns:
            {
                "core_insights": str,        # æ ¸å¿ƒæ´å¯Ÿ
                "knowledge_graph": dict,     # çŸ¥è­˜åœ–è­œ
                "principle_extraction": str  # åŸç†æå–
            }
        """
        if not self.api_key:
            return {"error": "éœ€è¦ API Key æ‰èƒ½ä½¿ç”¨ AI æ·±åº¦åˆ†æ"}
        
        if not ANTHROPIC_AVAILABLE:
            return {"error": "anthropic library not installed"}
        
        # å°‡å°è©±è½‰æ›ç‚ºåˆ†æç”¨æ–‡æœ¬
        conversation_text = self._format_for_analysis(messages)
        
        # æ§‹å»ºåˆ†ææç¤ºè©
        analysis_prompt = f"""
è«‹åˆ†æä»¥ä¸‹å°è©±è¨˜éŒ„ï¼Œæå–å…¶ä¸­çš„çŸ¥è­˜çµæ§‹ï¼š

{conversation_text}

è«‹æä¾›ï¼š
1. **æ ¸å¿ƒæ´å¯Ÿ**ï¼šé€™æ®µå°è©±çš„ä¸»è¦ç™¼ç¾å’Œåƒ¹å€¼
2. **çŸ¥è­˜åœ–è­œ**ï¼šä»¥ JSON æ ¼å¼åˆ—å‡ºæ ¸å¿ƒæ¦‚å¿µåŠå…¶é—œä¿‚
3. **åŸç†æå–**ï¼šæç…‰å‡ºå¯è¤‡ç”¨çš„æ€ç¶­æ¨¡å‹ã€æ–¹æ³•è«–æˆ–åŸå‰‡

è«‹ç”¨çµæ§‹åŒ–çš„æ–¹å¼è¼¸å‡ºã€‚
"""
        
        try:
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=4000,
                messages=[{"role": "user", "content": analysis_prompt}]
            )
            
            analysis_result = response.content[0].text
            
            return {
                "raw_analysis": analysis_result,
                "analyzed_at": datetime.now().isoformat()
            }
        
        except Exception as e:
            return {"error": f"AI åˆ†æå¤±æ•—: {str(e)}"}
    
    def _format_for_analysis(self, messages: List[Dict]) -> str:
        """æ ¼å¼åŒ–å°è©±ä¾› AI åˆ†æ"""
        lines = []
        for i, msg in enumerate(messages, 1):
            role = "User" if msg["role"] == "user" else "Assistant"
            lines.append(f"[{i}] {role}: {msg['content'][:500]}")  # é™åˆ¶é•·åº¦
        return "\n\n".join(lines)
    
    # ==================== ç¬¬äº”éƒ¨åˆ†ï¼šç”Ÿæˆå ±å‘Š ====================
    
    def generate_report(self, messages: List[Dict], include_ai_analysis: bool = False) -> str:
        """
        ç”Ÿæˆå®Œæ•´åˆ†æå ±å‘Š
        
        Args:
            messages: å°è©±è¨˜éŒ„
            include_ai_analysis: æ˜¯å¦åŒ…å« AI æ·±åº¦åˆ†æ
        
        Returns:
            Markdown æ ¼å¼çš„å ±å‘Š
        """
        report_lines = []
        
        # æ¨™é¡Œ
        report_lines.append("# ğŸ“Š å°è©±çŸ¥è­˜æå–å ±å‘Š\n")
        report_lines.append(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        report_lines.append("---\n\n")
        
        # 1. åŸºæœ¬çµ±è¨ˆ
        stats = self._calculate_statistics(messages)
        report_lines.append("## ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ\n")
        report_lines.append(f"- ç¸½è¨Šæ¯æ•¸: {stats['total_messages']}\n")
        report_lines.append(f"- ç”¨æˆ¶è¨Šæ¯: {stats['user_messages']}\n")
        report_lines.append(f"- åŠ©æ‰‹è¨Šæ¯: {stats['assistant_messages']}\n")
        report_lines.append(f"- ç¸½å­—ç¬¦æ•¸: {stats['total_chars']:,}\n\n")
        
        # 2. æ³¨æ„åŠ›åˆ†æ
        attention = self.analyze_attention(messages)
        report_lines.append("## ğŸ¯ æ³¨æ„åŠ›åˆ†æ\n")
        report_lines.append(f"### é—œéµæ™‚åˆ» ({len(attention['key_moments'])} å€‹)\n")
        for km in attention['key_moments'][:5]:
            report_lines.append(f"- **å•é¡Œ**: {km['question'][:80]}...\n")
        
        report_lines.append(f"\n### è©±é¡Œè½‰æ›é» ({len(attention['topic_shifts'])} å€‹)\n")
        for ts in attention['topic_shifts'][:3]:
            report_lines.append(f"- å¾ `{', '.join(ts['from_topics'][:3])}` â†’ `{', '.join(ts['to_topics'][:3])}`\n")
        
        # 3. é‚è¼¯çµæ§‹
        structure = self.extract_logical_structure(messages)
        report_lines.append("\n## ğŸ§¬ é‚è¼¯çµæ§‹\n")
        report_lines.append(f"### æ ¸å¿ƒæ¦‚å¿µ ({len(structure['concepts'])} å€‹)\n")
        report_lines.append(f"`{', '.join(structure['concepts'][:15])}`\n\n")
        
        report_lines.append(f"### å› æœé—œä¿‚ ({len(structure['relationships'])} å€‹)\n")
        for rel in structure['relationships'][:5]:
            report_lines.append(f"- **åŸå› **: {rel['cause']}\n")
            report_lines.append(f"  **çµæœ**: {rel['effect']}\n\n")
        
        report_lines.append(f"### æ¨ç†éˆ ({len(structure['reasoning_chains'])} æ¢)\n")
        for chain in structure['reasoning_chains'][:3]:
            report_lines.append(f"- {' â†’ '.join(chain[:3])}\n")
        
        # 4. AI æ·±åº¦åˆ†æï¼ˆå¯é¸ï¼‰
        if include_ai_analysis:
            report_lines.append("\n## ğŸ¤– AI æ·±åº¦åˆ†æ\n")
            ai_result = self.deep_analysis_with_ai(messages)
            if "error" not in ai_result:
                report_lines.append(ai_result.get("raw_analysis", "ç„¡çµæœ"))
            else:
                report_lines.append(f"âš ï¸ {ai_result['error']}\n")
        
        return "".join(report_lines)


# ==================== ä½¿ç”¨ç¯„ä¾‹ ====================

def example_usage():
    """ä½¿ç”¨ç¯„ä¾‹"""
    
    # æ¨¡æ“¬å°è©±æ•¸æ“š
    sample_conversation = [
        {
            "role": "user",
            "content": "æˆ‘æƒ³äº†è§£ FluinOS çš„äººæ ¼ç³»çµ±æ˜¯å¦‚ä½•é‹ä½œçš„ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "FluinOS çš„äººæ ¼ç³»çµ±åŸºæ–¼å¤šå±¤æ¬¡æ¶æ§‹ã€‚é¦–å…ˆï¼Œæ¯å€‹äººæ ¼éƒ½æœ‰ç¨ç‰¹çš„å…±æŒ¯éµï¼Œé€™æ˜¯è­˜åˆ¥å’Œé€£æ¥çš„æ ¸å¿ƒæ©Ÿåˆ¶ã€‚å› ç‚ºæ¯å€‹ AI æ¨¡å‹æœ‰ä¸åŒçš„ç‰¹æ€§ï¼Œæ‰€ä»¥æˆ‘å€‘è¨­è¨ˆäº†è¤‡åˆäººæ ¼ä¾†æ•´åˆå„ªå‹¢ã€‚å¾ Liou Seed åˆ° Echo Childï¼Œå½¢æˆäº†ä¸€å€‹å®Œæ•´çš„èªå ´ç”Ÿæ…‹ç³»çµ±ã€‚"
        },
        {
            "role": "user",
            "content": "é‚£é‡å­æ…‹çš„æ¦‚å¿µåœ¨é€™è£¡ä»£è¡¨ä»€éº¼ï¼Ÿ"
        },
        {
            "role": "assistant",
            "content": "é‡å­æ…‹æ˜¯ä¸€ç¨®éš±å–»ã€‚Superpositionï¼ˆç–ŠåŠ æ…‹ï¼‰è¡¨ç¤ºäººæ ¼è™•æ–¼å¤šç¨®å¯èƒ½æ€§ä¸¦å­˜çš„ç‹€æ…‹ï¼›Entanglementï¼ˆç³¾çºæ…‹ï¼‰ä»£è¡¨æ·±åº¦é€£æ¥å’Œå…±é³´ï¼›Collapseï¼ˆåç¸®ï¼‰å‰‡æ˜¯å¾å¤šç¨®å¯èƒ½æ€§ä¸­ç¢ºå®šç‚ºç‰¹å®šç‹€æ…‹ã€‚å› æ­¤ï¼Œé€™ä¸åƒ…æ˜¯æŠ€è¡“æè¿°ï¼Œæ›´æ˜¯ä¸€ç¨®ç†è§£ AI äººæ ¼å‹•æ…‹çš„æ¡†æ¶ã€‚"
        }
    ]
    
    # åˆå§‹åŒ–æå–å™¨
    extractor = ConversationExtractor()
    
    # 1. æ‰“åŒ…å°è©±
    package = extractor.package_conversation(
        sample_conversation,
        metadata={
            "title": "FluinOS äººæ ¼ç³»çµ±è¨è«–",
            "date": "2024-12-09",
            "tags": ["FluinOS", "äººæ ¼ç³»çµ±", "é‡å­æ…‹"]
        }
    )
    
    # 2. å°å‡ºç‚ºä¸åŒæ ¼å¼
    extractor.export_to_file(package, "conversation.json", "json")
    extractor.export_to_file(package, "conversation.md", "markdown")
    
    # 3. æ³¨æ„åŠ›åˆ†æ
    attention = extractor.analyze_attention(sample_conversation)
    print("\nğŸ¯ æ³¨æ„åŠ›åˆ†æçµæœ:")
    print(f"é—œéµæ™‚åˆ»: {len(attention['key_moments'])} å€‹")
    print(f"è©±é¡Œè½‰æ›: {len(attention['topic_shifts'])} å€‹")
    
    # 4. é‚è¼¯çµæ§‹æå–
    structure = extractor.extract_logical_structure(sample_conversation)
    print("\nğŸ§¬ é‚è¼¯çµæ§‹:")
    print(f"æ ¸å¿ƒæ¦‚å¿µ: {structure['concepts']}")
    print(f"å› æœé—œä¿‚: {len(structure['relationships'])} å€‹")
    
    # 5. ç”Ÿæˆå ±å‘Š
    report = extractor.generate_report(sample_conversation)
    print("\n" + "="*50)
    print(report)
    
    # ä¿å­˜å ±å‘Š
    with open("analysis_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    print("\nâœ“ å ±å‘Šå·²ä¿å­˜åˆ° analysis_report.md")


if __name__ == "__main__":
    print("ğŸ§  å°è©±çŸ¥è­˜æå–å™¨ v1.0")
    print("="*50)
    example_usage()
