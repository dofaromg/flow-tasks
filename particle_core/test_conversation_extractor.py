"""
Test suite for ConversationExtractor
å°è©±çŸ¥è­˜æå–å™¨æ¸¬è©¦å¥—ä»¶
"""

import os
import sys
import json
import tempfile

# Add particle_core/src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from conversation_extractor import ConversationExtractor


# Sample conversation data for testing
SAMPLE_CONVERSATION = [
    {
        "role": "user",
        "content": "ä»€éº¼æ˜¯ç²’å­èªè¨€ï¼Ÿ"
    },
    {
        "role": "assistant",
        "content": "ç²’å­èªè¨€æ˜¯ä¸€ç¨®å‰µæ–°çš„é‚è¼¯åŸ·è¡Œæ¡†æ¶ã€‚å®ƒå°‡è¨ˆç®—é‚è¼¯æŠ½è±¡ç‚ºç¨®å­æ¦‚å¿µï¼Œé€šéå…±æŒ¯æ©Ÿåˆ¶å¯¦ç¾è¨ˆç®—ã€‚å› ç‚ºå‚³çµ±ç·¨ç¨‹ç¯„å¼éæ–¼è¤‡é›œï¼Œæ‰€ä»¥æˆ‘å€‘è¨­è¨ˆäº†æ›´è‡ªç„¶çš„è¡¨é”æ–¹å¼ã€‚"
    },
    {
        "role": "user",
        "content": "å®ƒæœ‰ä»€éº¼å„ªå‹¢ï¼Ÿ"
    },
    {
        "role": "assistant",
        "content": "ä¸»è¦å„ªå‹¢åŒ…æ‹¬ï¼šé«˜å¯è®€æ€§ã€æ˜“ç¶­è­·æ€§ã€è·¨é ˜åŸŸé©ç”¨æ€§ã€‚ç”±æ–¼æ¡ç”¨äº†æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œå› æ­¤ç³»çµ±å…·æœ‰è‰¯å¥½çš„æ“´å±•æ€§ã€‚ç¸½ä¹‹ï¼Œé€™æ˜¯ä¸€ç¨®é¢å‘æœªä¾†çš„è¨ˆç®—ç¯„å¼ã€‚"
    }
]


def test_extractor_initialization():
    """æ¸¬è©¦æå–å™¨åˆå§‹åŒ–"""
    # ç„¡ API key åˆå§‹åŒ–
    extractor = ConversationExtractor()
    assert extractor is not None
    assert extractor.api_key is None
    
    # æœ‰ API key åˆå§‹åŒ–ï¼ˆä½†ä¸å¯¦éš›ä½¿ç”¨ï¼‰
    extractor_with_key = ConversationExtractor(api_key="test_key")
    assert extractor_with_key.api_key == "test_key"


def test_package_conversation():
    """æ¸¬è©¦å°è©±æ‰“åŒ…"""
    extractor = ConversationExtractor()
    
    metadata = {
        "title": "æ¸¬è©¦å°è©±",
        "date": "2026-01-04",
        "tags": ["test", "demo"]
    }
    
    package = extractor.package_conversation(SAMPLE_CONVERSATION, metadata)
    
    # é©—è­‰åŒ…çµæ§‹
    assert "metadata" in package
    assert "messages" in package
    assert "statistics" in package
    assert "exported_at" in package
    assert "version" in package
    
    # é©—è­‰å…ƒæ•¸æ“š
    assert package["metadata"]["title"] == "æ¸¬è©¦å°è©±"
    assert "test" in package["metadata"]["tags"]
    
    # é©—è­‰è¨Šæ¯
    assert len(package["messages"]) == 4
    assert package["messages"][0]["role"] == "user"


def test_calculate_statistics():
    """æ¸¬è©¦çµ±è¨ˆè¨ˆç®—"""
    extractor = ConversationExtractor()
    stats = extractor._calculate_statistics(SAMPLE_CONVERSATION)
    
    # é©—è­‰çµ±è¨ˆæ•¸æ“š
    assert stats["total_messages"] == 4
    assert stats["user_messages"] == 2
    assert stats["assistant_messages"] == 2
    assert stats["total_chars"] > 0
    assert stats["avg_user_length"] > 0
    assert stats["avg_assistant_length"] > 0


def test_export_json():
    """æ¸¬è©¦ JSON å°å‡º"""
    extractor = ConversationExtractor()
    package = extractor.package_conversation(SAMPLE_CONVERSATION)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        temp_path = f.name
    
    try:
        extractor.export_to_file(package, temp_path, "json")
        
        # é©—è­‰æª”æ¡ˆå­˜åœ¨
        assert os.path.exists(temp_path)
        
        # é©—è­‰å…§å®¹
        with open(temp_path, 'r', encoding='utf-8') as f:
            loaded_data = json.load(f)
        
        assert "messages" in loaded_data
        assert len(loaded_data["messages"]) == 4
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


def test_export_markdown():
    """æ¸¬è©¦ Markdown å°å‡º"""
    extractor = ConversationExtractor()
    package = extractor.package_conversation(
        SAMPLE_CONVERSATION,
        metadata={"title": "æ¸¬è©¦", "date": "2026-01-04", "tags": ["test"]}
    )
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
        temp_path = f.name
    
    try:
        extractor.export_to_file(package, temp_path, "markdown")
        
        # é©—è­‰æª”æ¡ˆå­˜åœ¨
        assert os.path.exists(temp_path)
        
        # é©—è­‰å…§å®¹
        with open(temp_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        assert "# æ¸¬è©¦" in content
        assert "User" in content or "ğŸ‘¤" in content
        assert "Assistant" in content or "ğŸ¤–" in content
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


def test_export_text():
    """æ¸¬è©¦ç´”æ–‡å­—å°å‡º"""
    extractor = ConversationExtractor()
    package = extractor.package_conversation(SAMPLE_CONVERSATION)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        temp_path = f.name
    
    try:
        extractor.export_to_file(package, temp_path, "txt")
        
        # é©—è­‰æª”æ¡ˆå­˜åœ¨
        assert os.path.exists(temp_path)
        
        # é©—è­‰å…§å®¹
        with open(temp_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        assert "[USER]" in content or "[ASSISTANT]" in content
        assert "=" in content  # åˆ†éš”ç·š
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


def test_extract_keywords():
    """æ¸¬è©¦é—œéµè©æå–"""
    extractor = ConversationExtractor()
    
    text = "ç²’å­èªè¨€ç³»çµ±æ¡ç”¨å‰µæ–°çš„é‚è¼¯åŸ·è¡Œæ¡†æ¶ï¼Œæä¾›äº†é«˜å¯è®€æ€§å’Œæ˜“ç¶­è­·æ€§ã€‚"
    keywords = extractor._extract_keywords(text, top_n=5)
    
    assert isinstance(keywords, list)
    assert len(keywords) <= 5
    # åœç”¨è©æ‡‰è©²è¢«éæ¿¾
    assert "çš„" not in keywords
    assert "äº†" not in keywords


def test_analyze_attention():
    """æ¸¬è©¦æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ†æ"""
    extractor = ConversationExtractor()
    
    # æ·»åŠ å•é¡Œä»¥è§¸ç™¼ key_moments
    conversation_with_question = SAMPLE_CONVERSATION + [
        {
            "role": "user",
            "content": "èƒ½è©³ç´°è§£é‡‹ä¸€ä¸‹ç²’å­èªè¨€çš„åŸ·è¡Œæ©Ÿåˆ¶å—ï¼Ÿé€™å€‹å•é¡Œå¾ˆé‡è¦ã€‚"
        },
        {
            "role": "assistant",
            "content": "ç•¶ç„¶å¯ä»¥ï¼ç²’å­èªè¨€çš„åŸ·è¡Œæ©Ÿåˆ¶åŸºæ–¼äº”å€‹éšæ®µï¼šSTRUCTUREï¼ˆçµæ§‹åŒ–ï¼‰ã€MARKï¼ˆæ¨™è¨˜ï¼‰ã€FLOWï¼ˆæµå‹•ï¼‰ã€RECURSEï¼ˆéæ­¸ï¼‰ã€STOREï¼ˆå­˜å„²ï¼‰ã€‚æ¯å€‹éšæ®µéƒ½æœ‰æ˜ç¢ºçš„è·è²¬ï¼Œç¢ºä¿é‚è¼¯åŸ·è¡Œçš„å®Œæ•´æ€§å’Œå¯è¿½æº¯æ€§ã€‚é€™ç¨®è¨­è¨ˆä½¿å¾—ç³»çµ±èƒ½å¤ è™•ç†è¤‡é›œçš„é‚è¼¯éˆï¼ŒåŒæ™‚ä¿æŒé«˜åº¦çš„æ¨¡çµ„åŒ–å’Œå¯ç¶­è­·æ€§ã€‚"
        }
    ]
    
    analysis = extractor.analyze_attention(conversation_with_question)
    
    # é©—è­‰åˆ†æçµæœçµæ§‹
    assert "key_moments" in analysis
    assert "topic_shifts" in analysis
    assert "high_density_segments" in analysis
    
    # é©—è­‰é¡å‹
    assert isinstance(analysis["key_moments"], list)
    assert isinstance(analysis["topic_shifts"], list)
    assert isinstance(analysis["high_density_segments"], list)


def test_extract_concepts():
    """æ¸¬è©¦æ¦‚å¿µæå–"""
    extractor = ConversationExtractor()
    
    text = "FlowAgent ç³»çµ±ä½¿ç”¨äº†ç²’å­èªè¨€æ©Ÿåˆ¶å’Œè¨˜æ†¶å°å­˜ç³»çµ±ã€‚Kubernetes æ¶æ§‹æä¾›äº†å®¹å™¨ç·¨æ’èƒ½åŠ›ã€‚"
    concepts = extractor._extract_concepts(text)
    
    assert isinstance(concepts, list)
    # æ‡‰è©²èƒ½æå–åˆ°ä¸€äº›æ¦‚å¿µ
    assert len(concepts) >= 0


def test_extract_causal_relations():
    """æ¸¬è©¦å› æœé—œä¿‚æå–"""
    extractor = ConversationExtractor()
    
    text = "å› ç‚ºç³»çµ±éœ€è¦é«˜å¯ç”¨æ€§ï¼Œæ‰€ä»¥æˆ‘å€‘æ¡ç”¨äº†åˆ†ä½ˆå¼æ¶æ§‹ã€‚ç”±æ–¼æ€§èƒ½è¦æ±‚å¾ˆé«˜ï¼Œå› æ­¤ä½¿ç”¨äº†ç·©å­˜æ©Ÿåˆ¶ã€‚"
    relations = extractor._extract_causal_relations(text)
    
    assert isinstance(relations, list)
    if len(relations) > 0:
        assert "cause" in relations[0]
        assert "effect" in relations[0]
        assert "type" in relations[0]


def test_extract_reasoning_chains():
    """æ¸¬è©¦æ¨ç†éˆæå–"""
    extractor = ConversationExtractor()
    
    text = "é¦–å…ˆéœ€è¦ç†è§£åŸºç¤æ¦‚å¿µã€‚ç†è§£æ¦‚å¿µå¾Œå¯ä»¥é–‹å§‹å¯¦ä½œã€‚å› æ­¤ï¼Œå¾ªåºæ¼¸é€²æ˜¯æœ€å¥½çš„å­¸ç¿’æ–¹å¼ã€‚"
    chains = extractor._extract_reasoning_chains(text)
    
    assert isinstance(chains, list)
    # æ¨ç†éˆæ‡‰è©²æ˜¯å­—ä¸²åˆ—è¡¨çš„åˆ—è¡¨
    for chain in chains:
        assert isinstance(chain, list)


def test_extract_conclusions():
    """æ¸¬è©¦çµè«–æå–"""
    extractor = ConversationExtractor()
    
    text = "ç¶“éåˆ†æï¼Œæˆ‘å€‘ç™¼ç¾ä¸‰å€‹é—œéµå•é¡Œã€‚ç¶œä¸Šæ‰€è¿°ï¼Œç³»çµ±éœ€è¦é€²è¡Œå„ªåŒ–ã€‚ç¸½ä¹‹ï¼Œé€™æ˜¯ä¸€å€‹é‡è¦çš„æ”¹é€²æ–¹å‘ã€‚"
    conclusions = extractor._extract_conclusions(text)
    
    assert isinstance(conclusions, list)
    # æ‡‰è©²èƒ½æ‰¾åˆ°ä¸€äº›çµè«–
    if len(conclusions) > 0:
        assert isinstance(conclusions[0], str)


def test_extract_logical_structure():
    """æ¸¬è©¦é‚è¼¯çµæ§‹æå–"""
    extractor = ConversationExtractor()
    
    structure = extractor.extract_logical_structure(SAMPLE_CONVERSATION)
    
    # é©—è­‰çµæ§‹
    assert "concepts" in structure
    assert "relationships" in structure
    assert "reasoning_chains" in structure
    assert "conclusions" in structure
    
    # é©—è­‰é¡å‹
    assert isinstance(structure["concepts"], list)
    assert isinstance(structure["relationships"], list)
    assert isinstance(structure["reasoning_chains"], list)
    assert isinstance(structure["conclusions"], list)


def test_generate_report():
    """æ¸¬è©¦å ±å‘Šç”Ÿæˆ"""
    extractor = ConversationExtractor()
    
    # ä¸ä½¿ç”¨ AI åˆ†æ
    report = extractor.generate_report(SAMPLE_CONVERSATION, include_ai_analysis=False)
    
    # é©—è­‰å ±å‘Šå…§å®¹
    assert isinstance(report, str)
    assert len(report) > 0
    assert "å°è©±çŸ¥è­˜æå–å ±å‘Š" in report
    assert "åŸºæœ¬çµ±è¨ˆ" in report
    assert "æ³¨æ„åŠ›åˆ†æ" in report
    assert "é‚è¼¯çµæ§‹" in report


def test_deep_analysis_without_api_key():
    """æ¸¬è©¦ç„¡ API key çš„ AI åˆ†æ"""
    extractor = ConversationExtractor()
    
    result = extractor.deep_analysis_with_ai(SAMPLE_CONVERSATION)
    
    # æ‡‰è©²è¿”å›éŒ¯èª¤è¨Šæ¯
    assert "error" in result
    assert "API Key" in result["error"]


def test_format_for_analysis():
    """æ¸¬è©¦åˆ†ææ ¼å¼åŒ–"""
    extractor = ConversationExtractor()
    
    formatted = extractor._format_for_analysis(SAMPLE_CONVERSATION)
    
    assert isinstance(formatted, str)
    assert "User" in formatted or "Assistant" in formatted
    assert len(formatted) > 0


def test_export_yaml():
    """æ¸¬è©¦ YAML å°å‡º"""
    extractor = ConversationExtractor()
    package = extractor.package_conversation(SAMPLE_CONVERSATION)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
        temp_path = f.name
    
    try:
        extractor.export_to_file(package, temp_path, "yaml")
        
        # é©—è­‰æª”æ¡ˆå­˜åœ¨
        assert os.path.exists(temp_path)
        
        # é©—è­‰å…§å®¹
        with open(temp_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        assert "messages:" in content or "metadata:" in content
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


def test_export_csv():
    """æ¸¬è©¦ CSV å°å‡º"""
    extractor = ConversationExtractor()
    package = extractor.package_conversation(SAMPLE_CONVERSATION)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
        temp_path = f.name
    
    try:
        extractor.export_to_file(package, temp_path, "csv")
        
        # é©—è­‰æª”æ¡ˆå­˜åœ¨
        assert os.path.exists(temp_path)
        
        # é©—è­‰å…§å®¹
        with open(temp_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        assert "Index" in content
        assert "Role" in content
        assert "Content" in content
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


def test_export_html():
    """æ¸¬è©¦ HTML å°å‡º"""
    extractor = ConversationExtractor()
    package = extractor.package_conversation(
        SAMPLE_CONVERSATION,
        metadata={"title": "æ¸¬è©¦", "date": "2026-01-05", "tags": ["test"]}
    )
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False) as f:
        temp_path = f.name
    
    try:
        extractor.export_to_file(package, temp_path, "html")
        
        # é©—è­‰æª”æ¡ˆå­˜åœ¨
        assert os.path.exists(temp_path)
        
        # é©—è­‰å…§å®¹
        with open(temp_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        assert "<!DOCTYPE html>" in content
        assert "<html" in content
        assert "æ¸¬è©¦" in content
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


def test_export_xml():
    """æ¸¬è©¦ XML å°å‡º"""
    extractor = ConversationExtractor()
    package = extractor.package_conversation(SAMPLE_CONVERSATION)
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.xml', delete=False) as f:
        temp_path = f.name
    
    try:
        extractor.export_to_file(package, temp_path, "xml")
        
        # é©—è­‰æª”æ¡ˆå­˜åœ¨
        assert os.path.exists(temp_path)
        
        # é©—è­‰å…§å®¹
        with open(temp_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        assert '<?xml version="1.0" encoding="UTF-8"?>' in content
        assert "<conversation" in content
        assert "<messages>" in content
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


# åŸ·è¡Œæ¸¬è©¦
if __name__ == "__main__":
    print("ğŸ§ª åŸ·è¡Œå°è©±çŸ¥è­˜æå–å™¨æ¸¬è©¦...")
    print("=" * 60)
    
    # æ‰‹å‹•åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    test_functions = [
        test_extractor_initialization,
        test_package_conversation,
        test_calculate_statistics,
        test_export_json,
        test_export_markdown,
        test_export_text,
        test_export_yaml,
        test_export_csv,
        test_export_html,
        test_export_xml,
        test_extract_keywords,
        test_analyze_attention,
        test_extract_concepts,
        test_extract_causal_relations,
        test_extract_reasoning_chains,
        test_extract_conclusions,
        test_extract_logical_structure,
        test_generate_report,
        test_deep_analysis_without_api_key,
        test_format_for_analysis,
    ]
    
    passed = 0
    failed = 0
    
    for test_func in test_functions:
        try:
            test_func()
            print(f"âœ“ {test_func.__name__}")
            passed += 1
        except Exception as e:
            print(f"âœ— {test_func.__name__}: {e}")
            failed += 1
    
    print("=" * 60)
    print(f"æ¸¬è©¦çµæœ: {passed} é€šé, {failed} å¤±æ•—")
    
    if failed == 0:
        print("âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼")
    else:
        print(f"âš ï¸  æœ‰ {failed} å€‹æ¸¬è©¦å¤±æ•—")
